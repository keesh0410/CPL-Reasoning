round: 1

# llm
policy_model_dir: ./models/policy_model_round1
value_model_dir: ./models/value_model_round1

# sampling_params
temperature: 0.7
n_generate_samples: 3
stop: ["<endstep>", "<endsolution>", "Question:"]
max_tokens: 1500

# mcts
iterations: 200
max_depth: 6
positive_reward: 1.0
negative_reward: -1.0


step_delim: "<endstep>\n"
seed: 1234
batch_size: -1
